{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validity_check(image, conv_filter, padding, stride):\n",
    "    \n",
    "    is_valid = True\n",
    "    image_shape = (np.shape(image))\n",
    "    filter_shape = (np.shape(conv_filter))\n",
    "    \n",
    "\n",
    "    if len(image_shape) != len(filter_shape) - 1:\n",
    "        print('Dimensions of both image and filter should be equal')\n",
    "        is_valid = False\n",
    "    \n",
    "    if len(image_shape) == 3 or len(filter_shape) > 3:\n",
    "        if image_shape[-1] != filter_shape[-1]:\n",
    "            print('Number of channels in both image and filter should be equal')\n",
    "            is_valid = False\n",
    "        \n",
    "    if filter_shape[1] != filter_shape[2]:\n",
    "        print(\"Filter should be of a square matrix\")\n",
    "        is_valid = False\n",
    "        \n",
    "        \n",
    "\n",
    "    if filter_shape[1] % 2 == 0:\n",
    "        print('dimensions of filter should be of odd dimensions not even')\n",
    "        is_valid = False\n",
    "    \n",
    "\n",
    "    '''\n",
    "    convolution_result is the array we obtain after running the filter all over the image\n",
    "    '''    \n",
    "    if is_valid:\n",
    "        '''one or more filters but only one channel (also for image)'''\n",
    "        if len(image_shape) == 2 and len(filter_shape) == 3:\n",
    "            \n",
    "            convolution_result = np.zeros((\n",
    "                            np.int16(((image_shape[0] + 2 * padding - filter_shape[1]) / stride) + 1),\n",
    "                            np.int16(((image_shape[1] + 2 * padding - filter_shape[2]) / stride) + 1)))\n",
    "            \n",
    "        '''one or more filters with more than one channel (also for image)'''\n",
    "        if len(image_shape) == 3 and len(filter_shape) == 4:\n",
    "            convolution_result = np.zeros((\n",
    "                            np.int16(((image_shape[0] + 2 * padding - filter_shape[1]) / stride) + 1),\n",
    "                            np.int16(((image_shape[1] + 2 * padding - filter_shape[2]) / stride) + 1),\n",
    "                            image_shape[3]))\n",
    "    else:\n",
    "        convolution_result = -1\n",
    "    \n",
    "    return [is_valid, convolution_result]\n",
    "\n",
    "\n",
    "def Relu(x):\n",
    "    indices = np.where(x < 0)\n",
    "    x[indices] = 0\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The dimensions represent height, width and no_of_channels in the input image and filters\n",
    "'''\n",
    "\n",
    "\n",
    "class Conv_pool:\n",
    "    '''\n",
    "    self.conv_result, self.pooling_result and self.relu_result  are of shape (m, n, o, p)\n",
    "    m - length of  conv_result (or pooling_result or relu_result) - no of images\n",
    "    n - number of different conv_results (produced by each filter in the input) or pooling_results \n",
    "    0 - number of rows in each entry in  conv_result (or pooling_result)\n",
    "    p - number of columns in each entry in conv_result (or pooling_result)\n",
    "    '''\n",
    "    def __init__(self, image, conv_filter, conv_bias, padding, stride, pooling_filter_size, pooling_filter_stride):\n",
    "        self.curr_image         = image\n",
    "        self.conv_filter        = conv_filter\n",
    "        self.conv_bias          = conv_bias\n",
    "        self.conv_filter_stride = stride\n",
    "        self.pool_filter_size   = pooling_filter_size\n",
    "        self.pool_filter_stride = pooling_filter_stride\n",
    "        self.padding            = padding\n",
    "        self.conv_result        = np.array([])\n",
    "        self.relu_result        = np.array([])\n",
    "        self.pooling_result     = np.array([])\n",
    "            \n",
    "    \n",
    "    \n",
    "    #####################################################\n",
    "    \n",
    "    def apply_convolution_every_image(self, convolution_result):\n",
    "        image        = self.curr_image\n",
    "        conv_filter  = self.conv_filter\n",
    "        stride       = self.conv_filter_stride\n",
    "        image_shape  = np.shape(image)\n",
    "        filter_shape = np.shape(conv_filter)\n",
    "        \n",
    "        no_of_filters         = filter_shape[0]\n",
    "        convoluted_image_list = []\n",
    "        \n",
    "        '''this loop runs for all the different filters in the conv_filter'''\n",
    "        for filter_num in range(0, no_of_filters):\n",
    "            convoluted_image = np.array([])\n",
    "            filter_ = conv_filter[filter_num, :]\n",
    "    \n",
    "            '''if image has more than one channel'''\n",
    "            if len(image_shape) == 3 and image_shape[-1] == filter_shape[-1]:\n",
    "\n",
    "                convoluted_image = self.convolve_the_image_by_filter(image[:, :, 0], filter_[:, :, 0], \n",
    "                                                                   convolution_result)\n",
    "                for channel in range(1, filter_shape[-1]):\n",
    "                    convoluted_image = convoluted_image + self.convolve_the_image_by_filter(image[:, :, channel], \n",
    "                                                                                             filter_[:, :, channel],\n",
    "                                                                                                 convolution_result)\n",
    "            '''if image has only one channel'''\n",
    "            if len(image_shape) == 2:\n",
    "                \n",
    "                convoluted_image = self.convolve_the_image_by_filter(image, filter_, convolution_result)\n",
    "            '''here, you used copy.copy() so as to refrain the convoluted_image_list getting over-written\n",
    "            by the new entries into the list'''\n",
    "            \n",
    "            convoluted_image = np.add(convoluted_image, self.conv_bias)\n",
    "            convoluted_image_list.append(copy.copy(convoluted_image))\n",
    "            \n",
    "        self.conv_result = np.array(convoluted_image_list)\n",
    "            \n",
    "    \n",
    "    \n",
    "    #########################################################\n",
    "    '''\n",
    "    when supplied with both image and filter, perform either convolution or pooling\n",
    "    '''\n",
    "    def apply_conv_or_pooling_on_data(self, image, filter_size, result, \n",
    "                                       stride_length, is_pooling, conv_filter = None):\n",
    "        \n",
    "        row_count = 0\n",
    "        column_count = 0\n",
    "\n",
    "        image_shape = np.shape(image)[1]\n",
    "        for row in range(0, image_shape, stride_length):\n",
    "            if row + filter_size <= image_shape:\n",
    "                column_count = 0\n",
    "                for column in range(0, image_shape, stride_length):\n",
    "\n",
    "                    if column + filter_size <= image_shape:\n",
    "                        \n",
    "                        '''present active region is the region in the image which will be multiplied\n",
    "                            by the filter'''\n",
    "                        if not is_pooling:\n",
    "                            \n",
    "                            present_active_region           = image[row : (row + filter_size), \n",
    "                                                                          column : (column + filter_size)]\n",
    "                            image_area_product_filter       = present_active_region * conv_filter\n",
    "                            sum_of_all_elements             = np.sum(image_area_product_filter)\n",
    "                            result[row_count, column_count] = sum_of_all_elements\n",
    "                        \n",
    "                        if is_pooling:\n",
    "                            \n",
    "                            active_region       = image[row : (row + filter_size), \n",
    "                                                                    column : (column + filter_size)] \n",
    "                            result[row_count, column_count] = np.max(active_region)\n",
    "\n",
    "                            \n",
    "                        column_count = column_count + 1\n",
    "            row_count = row_count + 1\n",
    "        \n",
    "        return result\n",
    "        \n",
    "        \n",
    "           \n",
    "    ######################################################\n",
    "    \n",
    "    def convolve_the_image_by_filter(self, image, conv_filter, convolution_result):\n",
    "        \n",
    "        stride      = self.conv_filter_stride\n",
    "        image_shape = np.shape(image)    \n",
    "        filter_size = np.shape(conv_filter)[0]\n",
    "        \n",
    "        result = self.apply_conv_or_pooling_on_data(image, filter_size, \n",
    "                                                    convolution_result, stride, False, conv_filter)\n",
    "        return result\n",
    "\n",
    "    \n",
    "    \n",
    "    ######################################################\n",
    "    \n",
    "    def relu_on_convolution_result(self):\n",
    "        convolution_result_          = self.conv_result\n",
    "        conv_result_shape            = np.shape(convolution_result_)\n",
    "        no_of_times_image_convoluted = conv_result_shape[0]\n",
    "        \n",
    "        \n",
    "            \n",
    "        relu_result_list = []\n",
    "\n",
    "        for result_num in range(0, no_of_times_image_convoluted):\n",
    "\n",
    "            current_convoluted_image = convolution_result_[result_num, :]\n",
    "            indices = np.where(current_convoluted_image <= 0)\n",
    "            current_convoluted_image[indices] = 0\n",
    "            relu_result_list.append(current_convoluted_image)\n",
    "\n",
    "        self.relu_result = np.array(relu_result_list)\n",
    "\n",
    "        \n",
    "    ######################################################\n",
    "    \n",
    "    '''max pooling'''    \n",
    "    def pooling_on_relu_result(self):\n",
    "        relu_result = self.relu_result\n",
    "        pool_size   = self.pool_filter_size\n",
    "        stride      = self.pool_filter_stride\n",
    "        \n",
    "\n",
    "        relu_result_shape            = np.shape(relu_result)\n",
    "        \n",
    "        no_of_relu_results_per_image = np.shape(relu_result)[0]\n",
    "        relu_result_shape_each_image = np.shape(relu_result)[1]\n",
    "\n",
    "        pooling_result_list = []\n",
    "        \n",
    "        \n",
    "    \n",
    "        for relu_result_num in range(0, no_of_relu_results_per_image):\n",
    "\n",
    "            curr_relu = relu_result[relu_result_num, :]\n",
    "\n",
    "            pooling_result   = np.zeros((np.uint16(((relu_result_shape_each_image - pool_size) / stride) + 1),\n",
    "                                   np.uint16(((relu_result_shape_each_image - pool_size) / stride) + 1)))\n",
    "\n",
    "            result = self.apply_conv_or_pooling_on_data(image = curr_relu, filter_size = pool_size, \n",
    "                                                        result = pooling_result, stride_length = stride, \n",
    "                                                        is_pooling = True)\n",
    "            pooling_result_list.append(result)\n",
    "\n",
    "\n",
    "            \n",
    "            \n",
    "        self.pooling_result = np.array(pooling_result_list)\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    ######################################################\n",
    "    \n",
    "    def pad_the_image(self):\n",
    "        pad_img = np.array()\n",
    "        if self.conv_filter.shape[1] == 3:\n",
    "            pad_img = np.zeros((30, 30))\n",
    "        \n",
    "        if self.conv_filter.shape[1] == 5:\n",
    "            pad_img = np.zeros((32, 32))\n",
    "            \n",
    "        pad_img[1 : self.curr_image.shape[1] + 1, 1 : self.curr_image.shape[1] + 1]  = self.curr_image\n",
    "        self.curr_image = pad_img\n",
    "    \n",
    "    \n",
    "    ######################################################\n",
    "    \n",
    "    def CNN(self):\n",
    "        \n",
    "        if self.padding:\n",
    "            self.pad_the_image()\n",
    "            \n",
    "        validity_convolution_result = validity_check(self.curr_image, self.conv_filter, \n",
    "                                                     self.padding, self.conv_filter_stride)\n",
    "        if validity_convolution_result[0]:\n",
    "            convolution_result = validity_convolution_result[1]\n",
    "            self.apply_convolution_every_image(convolution_result)\n",
    "            self.relu_on_convolution_result()\n",
    "            self.pooling_on_relu_result()\n",
    "\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Relu(x):\n",
    "    indices = np.where(x <= 0)\n",
    "    x[indices] = 0\n",
    "    return x\n",
    "    \n",
    "def softmax(x):\n",
    "    x = x.reshape(1, -1)\n",
    "    B = np.exp(x - max(x))\n",
    "    C = np.sum(B)\n",
    "    return B / C\n",
    "\n",
    "\n",
    "\n",
    "def cross_entropy(output, labels):\n",
    "    return -np.sum(labels * np.log(output))\n",
    "\n",
    "\n",
    "\n",
    "class fully_connected_layers_in_CNN:\n",
    "    \n",
    "    def __init__(self, conv_pool_object, labels, weights_1, weights_2, bias_1, bias_2, no_of_neurons):\n",
    "        self.conv_pool_result = conv_pool_object\n",
    "        self.pooling_result = conv_pool_object.pooling_result\n",
    "        self.labels = labels\n",
    "        self.pooling_result_shape = np.shape(self.pooling_result)\n",
    "        self.neurons = no_of_neurons\n",
    "    \n",
    "        self.weights_1 = weights_1\n",
    "        self.weights_2 = weights_2\n",
    "        self.bias_1    = bias_1\n",
    "        self.bias_2    = bias_2\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    ##########################################################\n",
    "    \n",
    "    def feed_forward_in_fc_layers(self):\n",
    "            \n",
    "        pooling_result     = self.pooling_result\n",
    "        no_of_neurons      = self.neurons\n",
    "\n",
    "        no_of_pool_results = self.pooling_result_shape[0]\n",
    "        no_of_rows         = self.pooling_result_shape[1]\n",
    "        no_of_columns      = self.pooling_result_shape[2]\n",
    "        self.fc_layer_1    = pooling_result.reshape(((no_of_pool_results * no_of_rows * no_of_columns), 1))\n",
    "        \n",
    "\n",
    "        self.z_1             = np.add(np.dot(self.weights_1.T, self.fc_layer_1), self.bias_1)\n",
    "        self.fc_layer_2      = Relu(self.z_1)\n",
    "        \n",
    "\n",
    "        self.z_2             = np.add(np.dot(self.weights_2.T, self.fc_layer_2), self.bias_2)\n",
    "        self.predicted_probs = softmax(self.z_2)\n",
    "          \n",
    "        self.loss = cross_entropy(self.predicted_probs, self.labels)\n",
    "        self.diff_btw_pred_and_actual_labels = self.predicted_probs - self.labels\n",
    "        \n",
    "        \n",
    "    \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class back_propagation_in_CNN:\n",
    "    \n",
    "    \n",
    "    ##########################################################\n",
    "    \n",
    "    def __init__(self, fc_layer_object):\n",
    "        self.fc_layer_object = fc_layer_object\n",
    "        self.conv_pool_result = fc_layer_object.conv_pool_result\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ##########################################################\n",
    "    \n",
    "    def get_the_index(self, conv_sub_array):\n",
    "        position_of_max_element = np.nanargmax(conv_sub_array)\n",
    "        index_of_max_element = np.unravel_index(position_of_max_element, conv_sub_array.shape)\n",
    "        return index_of_max_element\n",
    "    \n",
    "    \n",
    "    ##########################################################\n",
    "    \n",
    "    def backpropagation_wrt_pooling_result(self, derivative_pool_result):\n",
    "        \n",
    "        conv_result        = self.conv_pool_result.conv_result\n",
    "        pool_filter_size   = self.conv_pool_result.pool_filter_size\n",
    "        pool_filter_stride = self.conv_pool_result.pool_filter_stride\n",
    "        \n",
    "        no_of_convolved_images, no_of_rows, no_of_columns = np.shape(conv_result)\n",
    "        _, pool_row_length, _ = np.shape(derivative_pool_result)\n",
    "        output = np.zeros(np.shape(conv_result))\n",
    "    \n",
    "        row_count = 0\n",
    "        column_count = 0\n",
    "        for image_num in range(0, no_of_convolved_images):\n",
    "            current_image = conv_result[image_num, :]\n",
    "            row_count = 0\n",
    "            for row in range(0, no_of_rows, pool_filter_stride):\n",
    "                if row + pool_filter_size <= no_of_rows:\n",
    "                    column_count = 0\n",
    "                    for column in range(0, no_of_columns, pool_filter_stride):\n",
    "                        if column + pool_filter_size <= no_of_columns:\n",
    "                            image_sub_array = current_image[row : row + pool_filter_size, column : column + pool_filter_size]\n",
    "                            '''index of the max element in the original conv_image (in the area covered by pool filter)'''\n",
    "                            (i, j) = self.get_the_index(image_sub_array)\n",
    "                            if row_count <= pool_row_length:\n",
    "                                output[image_num, row + i, column + j] = derivative_pool_result[image_num, \n",
    "                                                                                            row_count, column_count]\n",
    "                            column_count = column_count + 1\n",
    "                \n",
    "                row_count = row_count + 1\n",
    "            \n",
    "        return output\n",
    "                              \n",
    "    \n",
    "    \n",
    "    ##########################################################\n",
    "    \n",
    "    def backpropagation_wrt_convolution_layer(self, der_conv_prev):\n",
    "                \n",
    "        conv_curr_image      = self.conv_pool_result.curr_image\n",
    "        conv_image_curr_list = [conv_curr_image]\n",
    "        conv_image_curr      = np.array(conv_image_curr_list)\n",
    "        conv_filter          = self.conv_pool_result.conv_filter\n",
    "        conv_bias            = self.conv_pool_result.conv_bias\n",
    "        filter_stride        = self.conv_pool_result.conv_filter_stride\n",
    "        no_of_filters, flt_size, no_of_columns_f = np.shape(conv_filter)\n",
    "        \n",
    "        len_of_shape_of_curr_image  = len(np.shape(conv_image_curr))\n",
    "        _,no_of_rows, no_of_columns = np.shape(conv_image_curr)\n",
    "\n",
    "        \n",
    "        der_wrt_filter = np.zeros(np.shape(conv_filter))\n",
    "        der_wrt_bias   = np.zeros(np.shape(conv_bias))\n",
    "        dconv_result   = np.zeros(np.shape(conv_image_curr))\n",
    "\n",
    "        \n",
    "        r_count = 0\n",
    "        c_count = 0\n",
    "        \n",
    "        for filter_num in range(0, no_of_filters):\n",
    "            r_count = 0\n",
    "            for r in range(0, no_of_rows, filter_stride):\n",
    "                if r + flt_size <= no_of_rows:\n",
    "                    c_count = 0\n",
    "                    for c in range(0, no_of_columns, filter_stride):\n",
    "                        if c + flt_size <= no_of_columns:\n",
    "                            '''update the filter'''\n",
    "                            der_conv_prev_ = der_conv_prev[filter_num]\n",
    "                            der_wrt_filter[filter_num] += der_conv_prev_[r_count, c_count] * conv_curr_image[r : r + flt_size,\n",
    "                                                                                                             c : c + flt_size]\n",
    "                            \n",
    "                            dconv_result[:, r : r + flt_size, c : c + flt_size] += der_conv_prev[filter_num, r_count, c_count] * conv_filter[filter_num, :]\n",
    "                            \n",
    "                            c_count = c_count + 1\n",
    "                r_count = r_count + 1\n",
    "        \n",
    "\n",
    "            der_wrt_bias = (der_conv_prev[filter_num])\n",
    "        \n",
    "        \n",
    "        return dconv_result, der_wrt_filter, der_wrt_bias\n",
    "                                \n",
    "    \n",
    "    \n",
    "    \n",
    "    ##########################################################\n",
    "    \n",
    "    def start_back_propagation(self):\n",
    "        \n",
    "        fc_layer_object = self.fc_layer_object\n",
    "        fc_layer_1      = fc_layer_object.fc_layer_1\n",
    "        \n",
    "        self.der_wrt_weights_2  = np.dot(fc_layer_object.z_1, fc_layer_object.diff_btw_pred_and_actual_labels)\n",
    "        \n",
    "        temporary_result = np.dot(fc_layer_object.weights_2,  \n",
    "                                  fc_layer_object.diff_btw_pred_and_actual_labels.T)\n",
    "        \n",
    "        self.der_wrt_weights_1 = np.dot(fc_layer_object.fc_layer_1, temporary_result.T)\n",
    "        \n",
    "        self.der_wrt_bias_2    = np.sum(fc_layer_object.diff_btw_pred_and_actual_labels, axis = 1).T\n",
    "        self.der_wrt_bias_1    = np.sum(temporary_result, axis = 1).reshape(fc_layer_object.bias_1.shape)\n",
    "        \n",
    "        der_fc_layer_1 = np.dot(fc_layer_object.weights_1, temporary_result)\n",
    "        reshaped_dfc_layer_1 = der_fc_layer_1.reshape(fc_layer_object.pooling_result_shape)\n",
    "        \n",
    "\n",
    "        '''back propagating through max-pooling layer (updating only those neurons with highest value)'''\n",
    "        der_pool_layer = self.backpropagation_wrt_pooling_result(reshaped_dfc_layer_1)\n",
    "        \n",
    "        '''back propagating through Relu layer'''\n",
    "        der_pool_layer[fc_layer_object.conv_pool_result.conv_result <= 0] = 0\n",
    "        der_image, der_filter, der_conv_bias = self.backpropagation_wrt_convolution_layer(der_pool_layer)\n",
    "        \n",
    "        self.return_result = [der_filter, der_conv_bias]\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##########################################################\n",
    "def read_data(directory_path, is_train_data):\n",
    "    if is_train_data:\n",
    "        mnsit_data = pd.read_csv(directory_path, header=None, low_memory = False)\n",
    "        mnsit_data.drop(0, axis = 0, inplace = True)\n",
    "        train_Y    = mnsit_data[0].astype(np.float32)\n",
    "        mnsit_data.drop(0, axis = 1, inplace = True)\n",
    "        mnsit_data = mnsit_data.astype(np.float32)\n",
    "\n",
    "        return mnsit_data, train_Y\n",
    "    \n",
    "    else:\n",
    "        mnsit_test = pd.read_csv(directory_path, header = None, low_memory = False)\n",
    "        mnsit_test.drop(0, axis = 0, inplace = True)\n",
    "        mnsit_test = mnsit_test.astype(np.float32)\n",
    "        \n",
    "        return mnsit_test\n",
    "    \n",
    "    \n",
    "    \n",
    "##########################################################\n",
    "def split_the_train_data(train_X, train_Y):\n",
    "    train_x, train_y, test_x, test_y = train_test_split(train_X, train_Y, test_size = 0.2, \n",
    "                                                        random_state = 42)\n",
    "    \n",
    "    return [[train_x, test_x], [train_y, test_y]]\n",
    "    \n",
    "##########################################################\n",
    "def convert_labels_to_one_hot_encoding_format(train_y, test_y):\n",
    "    one_hot_encoder = OneHotEncoder(categories = 'auto')\n",
    "    train_y_encoded = one_hot_encoder.fit_transform(train_y).toarray()\n",
    "    test_y_encoded  = one_hot_encoder.fit_transform(test_y).toarray()\n",
    "    return train_y_encoded.astype(np.float32), test_y_encoded.astype(np.float32)\n",
    "\n",
    "\n",
    "\n",
    "##########################################################\n",
    "def convert_input_to_image_format(data):\n",
    "    output = []\n",
    "    no_of_rows = np.shape(data)[0]\n",
    "    for row_num in range(0, no_of_rows):\n",
    "        output.append(data.iloc[row_num].values.reshape(28, 28))\n",
    "    \n",
    "    return np.array(output).astype(np.float32)\n",
    "    \n",
    "\n",
    "\n",
    "##########################################################\n",
    "def standardize_the_data(train_data, test_data):\n",
    "    scaler = StandardScaler().fit(train_data)\n",
    "    train_data_scaled = scaler.transform(train_data)\n",
    "    test_data_scaled  = scaler.transform(test_data)\n",
    "    return pd.DataFrame(train_data_scaled, dtype = np.float32), pd.DataFrame(test_data_scaled, dtype = np.float32)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/tensorflow-session/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/anaconda3/envs/tensorflow-session/lib/python3.6/site-packages/ipykernel_launcher.py:52: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n",
      "/anaconda3/envs/tensorflow-session/lib/python3.6/site-packages/ipykernel_launcher.py:53: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n"
     ]
    }
   ],
   "source": [
    "train_X, train_Y = read_data('/Users/vijay/Downloads/digit-recognizer/train.csv', True)\n",
    "test_X           = read_data('/Users/vijay/Downloads/digit-recognizer/test.csv', False)\n",
    "\n",
    "train_test_data  = split_the_train_data(train_X, train_Y)\n",
    "train_x, train_y = train_test_data[0]\n",
    "test_x, test_y   = train_test_data[1]\n",
    "\n",
    "train_x_standardized, test_x_standardized = standardize_the_data(train_x, test_x)\n",
    "train_x_reshaped = convert_input_to_image_format(train_x_standardized)\n",
    "test_x_reshaped   = convert_input_to_image_format(test_x_standardized)\n",
    "\n",
    "train_y_encoded, test_y_encoded = convert_labels_to_one_hot_encoding_format(train_y.values.reshape(-1, 1), \n",
    "                                                                           test_y.values.reshape(-1, 1))\n",
    "\n",
    "\n",
    "del(train_x)\n",
    "del(test_x)\n",
    "del(train_y)\n",
    "del(test_y)\n",
    "del(train_x_standardized)\n",
    "del(test_x_standardized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_filters_for_convolution(filter_size, no_of_filters, no_of_channels):\n",
    "    \n",
    "    if no_of_channels == 1:\n",
    "        conv_filters = np.zeros((no_of_filters, filter_size, filter_size))\n",
    "        for i in range(0, no_of_filters):\n",
    "            \n",
    "            filter_ = np.random.random((filter_size, filter_size))\n",
    "            conv_filters[i, :, :] = filter_\n",
    "            \n",
    "        return conv_filters\n",
    "    else:\n",
    "        conv_filters = np.zeros((no_of_filters, filter_size, filter_size, no_of_channels))\n",
    "        \n",
    "        for i in range(0, no_of_filters):\n",
    "            filter_ = np.random.random((filter_size, filter_size, no_of_channels))\n",
    "            conv_filters[i, :, :, :] = filter_\n",
    "\n",
    "        return conv_filters\n",
    "            \n",
    "            \n",
    "            \n",
    "    \n",
    "\n",
    "def get_weights_for_fc_layers(no_of_filters, image_size, conv_f_size, \n",
    "                                 pool_size, conv_f_stride, pool_stride, no_of_convolutions, padding, no_of_neurons):\n",
    "    for num in range(0, no_of_convolutions):\n",
    "        \n",
    "        conv_size  = np.int16(((image_size + 2 * padding - conv_f_size) / conv_f_stride) + 1)\n",
    "        pool_size  = np.uint16(((conv_size - pool_size) / pool_stride) + 1)\n",
    "        image_size = pool_size\n",
    "    \n",
    "    \n",
    "    weights_1 = np.random.random(((no_of_filters * image_size * image_size), no_of_neurons[0]))\n",
    "    weights_2 = np.random.random((no_of_neurons[0], no_of_neurons[1]))\n",
    "    \n",
    "    return weights_1, weights_2\n",
    "    \n",
    "\n",
    "def get_biases_for_convolution(bias_size):\n",
    "    conv_bias = np.full((bias_size, bias_size), 0.1)\n",
    "    return conv_bias\n",
    "    \n",
    "\n",
    "def get_biases_for_fc_layers():\n",
    "    bias_1 = np.random.random((1024, 1))\n",
    "    bias_2 = np.random.random((10, 1))\n",
    "    \n",
    "    return bias_1, bias_2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 336\n",
    "\n",
    "def update_parameters_for_each_batch(train_x, train_y, beta1, beta2, learning_rate, parameters, pooling_filter_size,\n",
    "                                        pooling_filter_stride, padding, stride, loss):\n",
    "    \n",
    "#     print('tain = ' + str(np.shape(train_x)))\n",
    "#     print('test - ' + str(np.shape(train_y)))\n",
    "    cf, cb, w1, w2, b1, b2 = parameters\n",
    "    conv_filter_shape = np.shape(cf)\n",
    "    conv_bias_shape   = np.shape(cb)\n",
    "    weights_1_shape   = np.shape(w1)\n",
    "    weights_2_shape   = np.shape(w2)\n",
    "    bias_1_shape      = np.shape(b1)\n",
    "    bias_2_shape      = np.shape(b2)\n",
    "    \n",
    "    \n",
    "    loss_        = 0\n",
    "    conv_filter_ = np.zeros(conv_filter_shape)\n",
    "    conv_bias_   = np.zeros(conv_bias_shape) \n",
    "    weights_1_   = np.zeros(weights_1_shape)\n",
    "    weights_2_   = np.zeros(weights_2_shape)\n",
    "    bias_1_      = np.zeros(bias_1_shape)\n",
    "    bias_2_      = np.zeros(bias_2_shape)\n",
    "\n",
    "    v_cf   = np.zeros(conv_filter_shape)\n",
    "    v_w_1  = np.zeros(weights_1_shape)\n",
    "    v_w_2  = np.zeros(weights_2_shape)\n",
    "    v_cb   = np.zeros(conv_bias_shape)\n",
    "    v_w1_b = np.zeros(bias_1_shape)\n",
    "    v_w2_b = np.zeros(bias_2_shape)\n",
    "\n",
    "    u_cf   = np.zeros(conv_filter_shape)\n",
    "    u_w_1  = np.zeros(weights_1_shape)\n",
    "    u_w_2  = np.zeros(weights_2_shape)\n",
    "    u_cb   = np.zeros(conv_bias_shape)\n",
    "    u_w1_b = np.zeros(bias_1_shape)\n",
    "    u_w2_b = np.zeros(bias_2_shape)\n",
    "\n",
    "\n",
    "\n",
    "    for image_num in range(0, batch_size):\n",
    "\n",
    "        conv_pool_object = Conv_pool(train_x[image_num], cf, cb, padding = 0, stride = 1, \n",
    "                                                    pooling_filter_size = 2, pooling_filter_stride = 2)\n",
    "        conv_pool_object.CNN()\n",
    "        \n",
    "        fc_layer_object  = fully_connected_layers_in_CNN(conv_pool_object, train_y[image_num], \n",
    "                                                         w1, w2, b1, b2, [1024, 10])\n",
    "        fc_layer_object.feed_forward_in_fc_layers()\n",
    "        \n",
    "        bp_object        = back_propagation_in_CNN(fc_layer_object)\n",
    "        bp_object.start_back_propagation()\n",
    "\n",
    "\n",
    "        d_conv_filter, d_conv_bias  = bp_object.return_result\n",
    "        d_wt_1, d_wt_2              = bp_object.der_wrt_weights_1, bp_object.der_wrt_weights_2, \n",
    "        d_bias_1, d_bias_2          = bp_object.der_wrt_bias_1, bp_object.der_wrt_bias_2\n",
    "        \n",
    "        \n",
    "        conv_filter_ += d_conv_filter\n",
    "        conv_bias_   += d_conv_bias\n",
    "        weights_1_   += d_wt_1\n",
    "        weights_2_   += d_wt_2\n",
    "        bias_1_      += d_bias_1\n",
    "        bias_2_      += d_bias_2\n",
    "        loss_        += fc_layer_object.loss\n",
    "            \n",
    "            \n",
    "            \n",
    "        v_cf = beta1 * v_cf + (1 - beta1) * (conv_filter_ / batch_size) \n",
    "        u_cf = beta2 * u_cf + (1 - beta2) * (conv_filter_ / batch_size) ** 2\n",
    "        cf  -= learning_rate * v_cf / np.sqrt(u_cf + 1e-7)\n",
    "\n",
    "        v_cb = beta1 * v_cb + (1 - beta1) * conv_bias_ / batch_size\n",
    "        u_cb = beta2 * u_cb + (1 - beta2) * (conv_bias_ / batch_size) ** 2\n",
    "        cb  -= learning_rate * v_cb / np.sqrt(u_cb + 1e-7)\n",
    "\n",
    "        v_w_1 = beta1 * v_w_1 + (1 - beta1) * weights_1_ / batch_size\n",
    "        u_w_1 = beta2 * u_w_1 + (1 - beta2) * (weights_1_ / batch_size) ** 2\n",
    "        w1   -= learning_rate * v_w_1/np.sqrt(u_w_1 + 1e-7)\n",
    "\n",
    "        v_w_2 = beta1 * v_w_2 + (1 - beta1) * weights_2_ / batch_size\n",
    "        u_w_2 = beta2 * u_w_2 + (1 - beta2) * (weights_2_ / batch_size) ** 2\n",
    "        w2   -= learning_rate * v_w_2/np.sqrt(u_w_2 + 1e-7)\n",
    "\n",
    "\n",
    "        v_w1_b = beta1 * v_w1_b + (1 - beta1) * bias_1_ / batch_size\n",
    "        u_w1_b = beta2 * u_w1_b + (1 - beta2) * (bias_1_ / batch_size) ** 2\n",
    "        b1    -= learning_rate * v_w1_b/np.sqrt(u_w1_b+1e-7)\n",
    "\n",
    "        v_w2_b = beta1 * v_w2_b + (1 - beta1) * bias_2_ / batch_size\n",
    "        u_w2_b = beta2 * u_w2_b + (1 - beta2) * (bias_2_ / batch_size) ** 2\n",
    "        b2    -= learning_rate * v_w2_b/np.sqrt(u_w2_b+1e-7)\n",
    "        \n",
    "        loss_ = loss_ / batch_size\n",
    "        loss.append(loss_)\n",
    "        parameters = [cf, cb, w1, w2, b1, b2] \n",
    "        \n",
    "        \n",
    "    return parameters, loss\n",
    "    \n",
    "        \n",
    "            \n",
    "\n",
    "\n",
    "def train(X, Y, img_size = 28, no_of_channels = 1, lr = 0.01, beta1 = 0.95, beta2 =0.99, \n",
    "                                    no_of_conv_filter = 8, batch_size = 336, no_of_epochs = 5):\n",
    "    \n",
    "    conv_filter = get_filters_for_convolution(filter_size = 3, no_of_filters = 32, no_of_channels = 1)\n",
    "    conv_bias   = get_biases_for_convolution(26)\n",
    "\n",
    "    weights_1, weights_2 = get_weights_for_fc_layers(32, 28, 3, 2, 1, 2, 1, 0, [1024, 10])\n",
    "    bias_1, bias_2       = get_biases_for_fc_layers()\n",
    "    \n",
    "    parameters = [conv_filter, conv_bias, weights_1, weights_2, bias_1, bias_2]\n",
    "    loss = []\n",
    "    no_of_rows = len(X)\n",
    "    \n",
    "    count = 0\n",
    "    for epoch in range(0, no_of_epochs):\n",
    "        X, Y = shuffle(X, Y)\n",
    "        print(epoch)\n",
    "        \n",
    "        for row in range(0, no_of_rows, batch_size):\n",
    "            if count <= 10:\n",
    "                print('            ' + str(count))\n",
    "                train_x = X[row : row + batch_size, :]\n",
    "                train_y  = Y[row : row + batch_size, :]\n",
    "                parameters, loss = update_parameters_for_each_batch(train_x, train_y, beta1, beta2, lr, parameters, \n",
    "                                                                     2, 2, 0, 1, loss)\n",
    "            count = count + 1\n",
    "        \n",
    "    return parameters, loss\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "            0\n",
      "            1\n",
      "            2\n",
      "            3\n",
      "            4\n",
      "            5\n",
      "            6\n",
      "            7\n",
      "            8\n",
      "            9\n",
      "            10\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "parameters, loss = train(X = train_x_reshaped, Y = train_y_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0.], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y_encoded[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 3, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(parameters[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "conv_filter = parameters[0]\n",
    "conv_bias   = parameters[1]\n",
    "fc_w1       = parameters[2]\n",
    "fc_w2       = parameters[3]\n",
    "fc_b1       = parameters[4]\n",
    "fc_b2       = parameters[5]\n",
    "\n",
    "# conv_pool_object = Conv_pool(train_x[image_num], cf, cb, padding = 0, stride = 1, \n",
    "#                                                     pooling_filter_size = 2, pooling_filter_stride = 2)\n",
    "# conv_pool_object.CNN()\n",
    "        \n",
    "#         fc_layer_object  = fully_connected_layers_in_CNN(conv_pool_object, train_y[image_num], \n",
    "#                                                          w1, w2, b1, b2, [1024, 10])\n",
    "#         fc_layer_object.feed_forward_in_fc_layers()\n",
    "        \n",
    "#         bp_object        = back_propagation_in_CNN(fc_layer_object)\n",
    "#         bp_object.start_back_propagation()\n",
    "\n",
    "\n",
    "test_conv_pool = Conv_pool(test_x_reshaped[1], conv_filter, conv_bias, padding = 0, stride = 1, pooling_filter_size = 2,\n",
    "                                        pooling_filter_stride = 2)\n",
    "test_conv_pool.CNN()\n",
    "\n",
    "test_fc_object = fully_connected_layers_in_CNN(test_conv_pool, test_y_encoded[1], fc_w1, fc_w2, fc_b1, fc_b2, [500, 10])\n",
    "test_fc_object.feed_forward_in_fc_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_fc_object.predicted_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.1, -0.9,  0.1,  0.1,  0.1,  0.1,  0.1,  0.1,  0.1,  0.1]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_fc_object.diff_btw_pred_and_actual_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33600, 28, 28)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(train_x_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
